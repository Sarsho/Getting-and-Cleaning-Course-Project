---
title: "CodeBook, Tidy Data, Averaged Means and Standard Deviations"
author: "Austin Overman"
date: "March 12, 2016"
output: html_document
---
### Part A) Original CodeBook information describing the data features as presented
####Feature Selection 

The features selected for this database come from the accelerometer and 
gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain 
signals (prefix 't' to denote time) were captured at a constant rate of 
50 Hz. Then they were filtered using a median filter and a 3rd order low 
pass Butterworth filter with a corner frequency of 20 Hz to remove noise. 
Similarly, the acceleration signal was then separated into body and gravity 
acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low 
pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived 
in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). 
Also the magnitude of these three-dimensional signals were calculated using 
the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, 
tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals 
producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, 
fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

* tBodyAcc-XYZ
* tGravityAcc-XYZ
* tBodyAccJerk-XYZ
* tBodyGyro-XYZ
* tBodyGyroJerk-XYZ
* tBodyAccMag
* tGravityAccMag
* tBodyAccJerkMag
* tBodyGyroMag
* tBodyGyroJerkMag
* fBodyAcc-XYZ
* fBodyAccJerk-XYZ
* fBodyGyro-XYZ
* fBodyAccMag
* fBodyAccJerkMag
* fBodyGyroMag
* fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 

* mean(): Mean value
* std(): Standard deviation
* mad(): Median absolute deviation 
* max(): Largest value in array
* min(): Smallest value in array
* sma(): Signal magnitude area
* energy(): Energy measure. Sum of the squares divided by the number of values. 
* iqr(): Interquartile range 
* entropy(): Signal entropy
* arCoeff(): Autorregresion coefficients with Burg order equal to 4
* correlation(): correlation coefficient between two signals
* maxInds(): index of the frequency component with largest magnitude
* meanFreq(): Weighted average of the frequency components to obtain a mean frequency
* skewness(): skewness of the frequency domain signal 
* kurtosis(): kurtosis of the frequency domain signal 
* bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.
* angle(): Angle between to vectors.

Additional vectors obtained by averaging the signals in a signal window sample. 
These are used on the angle() variable:

* gravityMean
* tBodyAccMean
* tBodyAccJerkMean
* tBodyGyroMean
* tBodyGyroJerkMean

The complete list of variables of each feature vector is available in 'features.txt'

### Part B) Combining, Reducing and Creating a Tidy Data Set

For this analysis, the final output will be the averages of the variables "means()" and "std()" for each of the signals and their respective orientation. 

To get to this final output, first the test and training data sets for the data described above in Part A along with their respective subject and activity name lists were combined and then "tidied" from a short or wide form data frame to a long form 10299 observations x 69 variable sized data frame called 'acc_stat' which contains the following grouping columns, signals and variables columns.

Grouping Columns: Total 2

* activity_name:    Factor w/ 6 levels      "LAYING",
                                            "SITTING", 
                                            "STANDING", 
                                            "WALKING",
                                            "WALKING_UPSTAIRS",
                                            "WALKING_DOWNSTAIRS"
* activity:         Factor w/ 6 levels      "1", "2", ..., "6"
* subject:          Factor w/ 30 levels     "1", "2", ..., "30"


Oriention Signals: Total 24 signals, or 1 each for the X, Y and Z orientation

* tBodyAcc-XYZ
* tGravityAcc-XYZ
* tBodyAccJerk-XYZ
* tBodyGyro-XYZ
* tBodyGyroJerk-XYZ
* fBodyAcc-XYZ
* fBodyAccJerk-XYZ
* fBodyGyro-XYZ

Magnitude Signals: Total 9

* tBodyAccMag
* tGravityAccMag
* tBodyAccJerkMag
* tBodyGyroMag
* tBodyGyroJerkMag
* fBodyAccMag
* fBodyAccJerkMag
* fBodyGyroMag
* fBodyGyroJerkMag

Variables : Total 3

* mean(): Mean value
* std(): Standard deviation

Therefore for each of the 33 signals there is both a mean() and std() value for a total of 66 independant variables, and the three grouping variables for a grand total of 69 columns.

The second step is to tidy this data frame further by melting the 66 independant variables by the grouping columns 'activity' and 'subject' to calculate the average for each of signals to form a smaller tidy data frame of 11880 observations x 4 variables called 'avg_stat' with the following variables:

* activity_name:    Factor w/ 6 levels      "LAYING",
                                            "SITTING", 
                                            "STANDING", 
                                            "WALKING",
                                            "WALKING_UPSTAIRS",
                                            "WALKING_DOWNSTAIRS"
* subject:          Factor w/ 30 levels     "1", "2", ..., "30"
* signal:           Factor w/ 66 levels     "tBodyAcc-mean()-X", "tBodyAcc-std()-Y" ....
                        The 33 signals described in Part A, for both the mean() and std()     
* average:          num                     [sample = 0.2216 -0.0405 -0.1132 -0.2489 0.7055 ...]
                        The averages for the mean and std for each of the 33 signals





